{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of E-MTAB-7407_ERS3861826.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agalvezm/ACE2_scRNAseq/blob/master/tcc/E_MTAB_7407_ERS3861826_from_gc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9ryXluJsJw9"
      },
      "source": [
        "# E-MTAB-7407_ERS3861826"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggNFAQJCRh6P"
      },
      "source": [
        "# define the values for the analysis\n",
        "\n",
        "# accession id for the data\n",
        "id = \"E-MTAB-7407\"\n",
        "samp_id = [\"ERS3861826\"]\n",
        "\n",
        "# If only bam available files, set bam = True, Fill link and filename\n",
        "bam = False\n",
        "\n",
        "# If fastq links available but are not ffq links\n",
        "fastq_ffqlinks = True\n",
        "\n",
        "if not bam:\n",
        "\n",
        "  # Copy and paste the links from the ACE2 scRNAseq datasets google  spreadsheet\n",
        "  links_raw = \"ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-7407/FCAImmP7462240_S1_L001_R1_001.fastq.gz\tftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-7407/FCAImmP7462240_S1_L001_R2_001.fastq.gz\"\n",
        "\n",
        "  # Convert it to a list where each link is an element\n",
        "  \n",
        "  fastqs = links_raw.split()\n",
        "\n",
        "no_samples = 1\n",
        "tissue = [\"skin\"] * no_samples\n",
        "\n",
        "cell_type = [\"CD45+\"] * no_samples\n",
        "\n",
        "condition = [\"female, 7 weeks gestation\"] * no_samples\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R3tPDqnoJUn"
      },
      "source": [
        "no_samples = 1\n",
        "\n",
        "fastqs_per_sample = [2] \n",
        "\n",
        "sample_id = samp_id\n",
        "\n",
        "database_id = [id] * no_samples\n",
        "\n",
        "# tissue = [\"\"] * no_samples\n",
        "\n",
        "# cell_type = [\"CD45+\"] * no_samples\n",
        "\n",
        "# condition = [\"male, 8 weeks gestation\"] * no_samples\n",
        "\n",
        "species = [\"human\"] * no_samples\n",
        "\n",
        "technology = [\"10xv2\"] * no_samples\n",
        "\n",
        "paper = [\"Sungnak et al 2020\"] * no_samples\n",
        "\n",
        "figure = [\"Fig 1\"] * no_samples\n",
        "\n",
        "\n",
        "# Set string variables for kb functions\n",
        "\n",
        "species_kb = species[0]\n",
        "\n",
        "technology_kb = technology[0]\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPwL0-_-KSAw"
      },
      "source": [
        "# Imports and installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HSlUGZEp3oP",
        "outputId": "9feeac81-9bca-47dd-dede-3f84bcc0a37b"
      },
      "source": [
        "# install and import necessary software\n",
        "\n",
        "# Install kb and scanpy\n",
        "!pip -q install kb-python \n",
        "!pip -q install scanpy\n",
        "\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Setup\n",
        "\n",
        "import anndata\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import matplotlib.patches as mpatches\n",
        "import scanpy as sc\n",
        "from scipy import stats\n",
        "\n",
        "from collections import OrderedDict\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
        "from matplotlib import cm\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "def nd(arr):\n",
        "    return np.asarray(arr).reshape(-1)\n",
        "def yex(ax):\n",
        "    lims = [np.min([ax.get_xlim(), ax.get_ylim()]),\n",
        "            np.max([ax.get_xlim(), ax.get_ylim()])]\n",
        "\n",
        "    # now plot both limits against eachother\n",
        "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.set_xlim(lims)\n",
        "    ax.set_ylim(lims)\n",
        "    return ax\n",
        "\n",
        "def trim_axs(axs, N):\n",
        "    \"\"\"little helper to massage the axs list to have correct length...\"\"\"\n",
        "    axs = axs.flat\n",
        "    for ax in axs[N:]:\n",
        "        ax.remove()\n",
        "    return axs[:N]\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "fsize=20\n",
        "\n",
        "plt.rcParams.update({'font.size': fsize})\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 59.1MB 77kB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 52.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 13.2MB 345kB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.3MB 48.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 55.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 7.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 40.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 6.8MB/s \n",
            "\u001b[?25h  Building wheel for loompy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for numpy-groupies (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V6FbosVrvP4"
      },
      "source": [
        "# Downloads: (bam (if bam) and index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q46hw4zqKUPS"
      },
      "source": [
        "if bam:\n",
        "\n",
        "  # Install bamtofastq from 10x website (only bam files available)\n",
        "  !wget http://cf.10xgenomics.com/misc/bamtofastq-1.2.0\n",
        "  !chmod +x bamtofastq-1.2.0\n",
        "  # Download the bam file\n",
        "  !wget -- continue ${BAM_LINK}\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDQlrjtqNF0m"
      },
      "source": [
        "if bam:\n",
        "  # Convert to fastq\n",
        "  !./bamtofastq-1.2.0 --reads-per-fastq=500000000 $bam_filename ./fastqs\\\n",
        "\n",
        "  # Remove original bam file to save space\n",
        "  !rm $bam_filename\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXRDRphvqcLe"
      },
      "source": [
        "# Store fastq names on a list\n",
        "\n",
        "if bam:\n",
        "  # cd into fastqs folder\n",
        "  %cd /content/fastqs\n",
        "\n",
        "  #store the name of the folder generated by bamtofastq\n",
        "  _filename = os.listdir()[0]\n",
        "\n",
        "  # cd into that folder\n",
        "  %cd $_filename\n",
        "\n",
        "  # store fastq names in a list\n",
        "  fastqs = os.listdir()\n",
        "\n",
        "\n",
        "  # Remove I1 and R3 reads not relevant for our analysis\n",
        "\n",
        "  # Initialize list containing elements to remove\n",
        "  remov_elem = []\n",
        "\n",
        "  print (\"\\n\\nThis is the complete list of fastqs:\\n -----------\")\n",
        "  for elem in fastqs:\n",
        "    print (elem)\n",
        "\n",
        "  # Search index (I1 or R3) fastqs and remove them from list\n",
        "  for elem in fastqs:\n",
        "    if re.search(\"_R3_\", elem) or re.search(\"_I1_\", elem):\n",
        "      remov_elem = remov_elem +[elem]\n",
        "\n",
        "  fastqs = [elem for elem in fastqs if elem not in remov_elem] \n",
        "\n",
        "  print (\"\\n\\nThis is the filtered list of fastqs:\\n -----------\")\n",
        "  for elem in fastqs:\n",
        "    print (elem)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnFcqcSgjLBw"
      },
      "source": [
        "# Remove fastqs that wont be analyzed to save space\n",
        "if bam:\n",
        "  for elem in remov_elem:\n",
        "    !rm $elem"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLVS8aB7Dm6J"
      },
      "source": [
        "if bam:\n",
        "  # sort fastqs alphabetically to get R1 and R2 in order\n",
        "  fastqs = sorted(fastqs)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE9gWbQgpBfR"
      },
      "source": [
        "# wget fastqs from non ffq links in fastqs folder\n",
        "if not bam and not fastq_ffqlinks:\n",
        "  !mkdir fastqs\n",
        "  %cd fastqs\n",
        "  for link in fastqs:\n",
        "    !wget $link --continue\n",
        "\n",
        "  # update fastqs variable with name of files\n",
        "  fastqs = sorted(os.listdir())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC9oETW1pE9t",
        "outputId": "ba465dae-3e7d-4e9c-9435-24e7daeebe50"
      },
      "source": [
        "if bam:\n",
        "  # Download the corresponding Kallisto index to folder containing fastqs\n",
        "  !kb ref -d $species_kb -i index.idx -g t2g.txt -f1 transcriptome.fasta\n",
        "\n",
        "if not bam and fastq_ffqlinks:\n",
        "  %cd /content\n",
        "\n",
        "  # Download the corresponding Kallisto index to content folder\n",
        "  !kb ref -d $species_kb -i index.idx -g t2g.txt -f1 transcriptome.fasta\n",
        "\n",
        "if not bam and not fastq_ffqlinks:\n",
        "  %cd /content/fastqs\n",
        "\n",
        "  # Download the corresponding Kallisto index to fastq folder\n",
        "  !kb ref -d $species_kb -i index.idx -g t2g.txt -f1 transcriptome.fasta"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "[2021-04-22 22:46:49,400]    INFO Downloading files for human from https://caltech.box.com/shared/static/v1nm7lpnqz5syh8dyzdk2zs8bglncfib.gz to tmp/v1nm7lpnqz5syh8dyzdk2zs8bglncfib.gz\n",
            "100% 2.23G/2.23G [02:57<00:00, 13.5MB/s]\n",
            "[2021-04-22 22:49:49,064]    INFO Extracting files from tmp/v1nm7lpnqz5syh8dyzdk2zs8bglncfib.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHVNa51Cp9Nr",
        "outputId": "46cca54e-406b-48e4-f67c-f810192ac9bf"
      },
      "source": [
        "# Check to make sure the metadata is in the right order after sorting\n",
        "print(fastqs)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-7407/FCAImmP7462240_S1_L001_R1_001.fastq.gz', 'ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-7407/FCAImmP7462240_S1_L001_R2_001.fastq.gz']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VInyuq1Dp7iz"
      },
      "source": [
        "# Process fastq files (modify kb command according to fastqs list)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcqtBuH-pRaX",
        "outputId": "ed2fa961-ef2c-4803-94ba-bffbdf49be31"
      },
      "source": [
        "fastqs"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-7407/FCAImmP7462240_S1_L001_R1_001.fastq.gz',\n",
              " 'ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-7407/FCAImmP7462240_S1_L001_R2_001.fastq.gz']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qFzPj-0kZTi",
        "outputId": "e8f75752-56f9-4d7c-a769-73ecd0405830"
      },
      "source": [
        "if no_samples == 1:\n",
        "\n",
        "  # Write the kb count command as a string with all fastqs of the list as an input\n",
        "  cmd = \"kb count --h5ad -i index.idx -g t2g.txt -x \" + technology_kb + \" -o tccoutput\" + sample_id[0] + \" \"\\\n",
        "  + \"--filter bustools --tcc -t 2 --overwrite \" + \"'\" +  \"' '\".join(fastqs) + \"'\"\n",
        "  \n",
        "  # Execute it\n",
        "  !$cmd\n",
        "\n",
        "# If more than one sample, iterate through fastqs accordingly\n",
        "else:\n",
        "\n",
        "  # Initializa counter for fastq files\n",
        "  j = 0\n",
        "\n",
        "  # Loop over samples for analysis\n",
        "  for i in range(no_samples):\n",
        "\n",
        "    fastqs_to_analyze = fastqs[j:j + fastqs_per_sample[i]]\n",
        "    # Write the kb count command as a string\n",
        "    cmd = \"kb count --h5ad -i ../index.idx -g ../t2g.txt -x \" + technology_kb + \" -o tccoutput\" + sample_id[i] + \" \\\n",
        "    --filter bustools --tcc -t 2 --overwrite \" + \"'\" +  \"' '\".join(fastqs_to_analyze) + \"'\"\n",
        "\n",
        "    # Execute it\n",
        "    !$cmd\n",
        "\n",
        "    # Update j to move to the next set of fastq\n",
        "    j = j + fastqs_per_sample[i]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "results = {}\n",
        "tcc_results = {}\n",
        "for sample in sample_id:\n",
        "  # Read the filtered gene count matrix\n",
        "  results[\"data_\" + sample] = anndata.read(\"/content/result\" + sample)\n",
        "\n",
        "\n",
        "for sample in sample_id:\n",
        "  output = \"bus_raw_\" + sample + \"_from_gc\"\n",
        "  !mkdir $output\n",
        "  folder_tcc = \"tccoutput\" + sample\n",
        "\n",
        "  # read tcc matrix\n",
        "  tcc_results[sample] = anndata.read(folder_tcc + \"/counts_unfiltered/adata.h5ad\")\n",
        "  # apply gene count matrix's filter\n",
        "  tcc_results[sample] = tcc_results[sample][results[\"data_\" + sample].obs.index.values]\n",
        "  # transfer obs data\n",
        "  tcc_results[sample].obs = results[\"data_\" + sample].obs\n",
        "  # transfer metadata\n",
        "  tcc_results[sample].uns = results[\"data_\" + sample].uns\n",
        "  # write tcc matrix\n",
        "  tcc_results[sample].write(\"/content/tcc_\" + sample)\n",
        "  #gzip tcc matrix\n",
        "  cmd = \"gzip /content/tcc_\" + sample\n",
        "  !$cmd\n",
        "  #gzip unfiltered bus file\n",
        "  cmd = \"gzip \" + folder_tcc + \"/output.unfiltered.bus\"\n",
        "  !$cmd\n",
        "  # move and re-name bus file with sample id\n",
        "  cmd = \"mv \" + folder_tcc + \"/output.unfiltered.bus.gz \" + output + \"/\" + sample +\".unfiltered.bus.gz\"\n",
        "  !$cmd\n",
        "  # gzip all unfiltered counts\n",
        "  cmd = \"gzip \" + folder_tcc + \"/counts_unfiltered/*\"\n",
        "  !$cmd\n",
        "\n",
        "  # move unfiltered counts for both\n",
        "  cmd = \"mv \" + folder_tcc + \"/counts_unfiltered \" + output + \"/tcc_unfiltered\"\n",
        "  !$cmd\n",
        "\n",
        "  cmd = \"mv \" + folder_tcc + \"/*.json \" + output \n",
        "  !$cmd\n",
        "  # zip all files\n",
        "  cmd = \"zip -r \"+ output + \".zip \" + output\n",
        "  !$cmd\n",
        "\n",
        "\n",
        "import time\n",
        "time.sleep(60000000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-04-22 22:50:29,809]    INFO Piping ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-7407/FCAImmP7462240_S1_L001_R1_001.fastq.gz to tccoutputERS3861826/tmp/FCAImmP7462240_S1_L001_R1_001.fastq.gz\n",
            "[2021-04-22 22:50:29,812]    INFO Piping ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-7407/FCAImmP7462240_S1_L001_R2_001.fastq.gz to tccoutputERS3861826/tmp/FCAImmP7462240_S1_L001_R2_001.fastq.gz\n",
            "[2021-04-22 22:50:29,813]    INFO Using index index.idx to generate BUS file to tccoutputERS3861826 from\n",
            "[2021-04-22 22:50:29,814]    INFO         tccoutputERS3861826/tmp/FCAImmP7462240_S1_L001_R1_001.fastq.gz\n",
            "[2021-04-22 22:50:29,814]    INFO         tccoutputERS3861826/tmp/FCAImmP7462240_S1_L001_R2_001.fastq.gz\n",
            "[2021-04-23 00:01:30,863]    INFO Sorting BUS file tccoutputERS3861826/output.bus to tccoutputERS3861826/tmp/output.s.bus\n",
            "[2021-04-23 00:06:30,721]    INFO Whitelist not provided\n",
            "[2021-04-23 00:06:30,722]    INFO Copying pre-packaged 10XV2 whitelist to tccoutputERS3861826\n",
            "[2021-04-23 00:06:30,880]    INFO Inspecting BUS file tccoutputERS3861826/tmp/output.s.bus\n",
            "[2021-04-23 00:06:59,678]    INFO Correcting BUS records in tccoutputERS3861826/tmp/output.s.bus to tccoutputERS3861826/tmp/output.s.c.bus with whitelist tccoutputERS3861826/10xv2_whitelist.txt\n",
            "[2021-04-23 00:07:30,395]    INFO Sorting BUS file tccoutputERS3861826/tmp/output.s.c.bus to tccoutputERS3861826/output.unfiltered.bus\n",
            "[2021-04-23 00:09:27,353]    INFO Generating count matrix tccoutputERS3861826/counts_unfiltered/cells_x_tcc from BUS file tccoutputERS3861826/output.unfiltered.bus\n",
            "[2021-04-23 00:10:56,927]    INFO Reading matrix tccoutputERS3861826/counts_unfiltered/cells_x_tcc.mtx\n",
            "[2021-04-23 00:12:18,768]    INFO Writing matrix to h5ad tccoutputERS3861826/counts_unfiltered/adata.h5ad\n",
            "[2021-04-23 00:12:42,493]    INFO Filtering with bustools\n",
            "[2021-04-23 00:12:42,511]    INFO Generating whitelist tccoutputERS3861826/filter_barcodes.txt from BUS file tccoutputERS3861826/output.unfiltered.bus\n",
            "[2021-04-23 00:12:43,461]    INFO Correcting BUS records in tccoutputERS3861826/output.unfiltered.bus to tccoutputERS3861826/tmp/output.unfiltered.c.bus with whitelist tccoutputERS3861826/filter_barcodes.txt\n",
            "[2021-04-23 00:13:23,223]    INFO Sorting BUS file tccoutputERS3861826/tmp/output.unfiltered.c.bus to tccoutputERS3861826/output.filtered.bus\n",
            "[2021-04-23 00:15:50,669]    INFO Generating count matrix tccoutputERS3861826/counts_filtered/cells_x_tcc from BUS file tccoutputERS3861826/output.filtered.bus\n",
            "[2021-04-23 00:17:24,854]    INFO Reading matrix tccoutputERS3861826/counts_filtered/cells_x_tcc.mtx\n",
            "[2021-04-23 00:18:42,352]    INFO Writing matrix to h5ad tccoutputERS3861826/counts_filtered/adata.h5ad\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  adding: bus_raw_ERS3861826_from_gc/ (stored 0%)\n",
            "  adding: bus_raw_ERS3861826_from_gc/run_info.json (deflated 43%)\n",
            "  adding: bus_raw_ERS3861826_from_gc/tcc_unfiltered/ (stored 0%)\n",
            "  adding: bus_raw_ERS3861826_from_gc/tcc_unfiltered/adata.h5ad.gz (deflated 5%)\n",
            "  adding: bus_raw_ERS3861826_from_gc/tcc_unfiltered/cells_x_tcc.mtx.gz (deflated 0%)\n",
            "  adding: bus_raw_ERS3861826_from_gc/tcc_unfiltered/cells_x_tcc.barcodes.txt.gz (deflated 1%)\n",
            "  adding: bus_raw_ERS3861826_from_gc/tcc_unfiltered/cells_x_tcc.ec.txt.gz (deflated 1%)\n",
            "  adding: bus_raw_ERS3861826_from_gc/inspect.json (deflated 57%)\n",
            "  adding: bus_raw_ERS3861826_from_gc/ERS3861826.unfiltered.bus.gz (deflated 5%)\n",
            "  adding: bus_raw_ERS3861826_from_gc/kb_info.json (deflated 74%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC2s3OqniY2N"
      },
      "source": [
        "bus only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDijOZzrqhN2"
      },
      "source": [
        "# Load unfiltered matrix and assign filters to each matrix individually"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkNLZh_pNFFw"
      },
      "source": [
        "## Load the unfiltered matrix (check dimensions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PppRNeV8AIyw"
      },
      "source": [
        "# Define dict to store data\n",
        "results = {}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "pKmtGf3c_BiZ"
      },
      "source": [
        "# load the unfiltered matrix\n",
        "for i in range(no_samples):\n",
        "  results[sample_id[i]] = anndata.read_h5ad(\"output\" + sample_id[i] + \"/counts_unfiltered/adata.h5ad\")\n",
        "  results[sample_id[i]].var[\"gene_id\"] = results[sample_id[i]].var.index.values\n",
        "\n",
        "  t2g = pd.read_csv(\"t2g.txt\", header=None, names=[\"tid\", \"gene_id\", \"gene_name\"], sep=\"\\t\")\n",
        "  t2g.index = t2g.gene_id\n",
        "  t2g = t2g.loc[~t2g.index.duplicated(keep='first')]\n",
        "\n",
        "  results[sample_id[i]].var[\"gene_name\"] = results[sample_id[i]].var.gene_id.map(t2g[\"gene_name\"])\n",
        "  results[sample_id[i]].var.index = results[sample_id[i]].var[\"gene_name\"]\n",
        "  print(\"The unfiltered matrix \" + sample_id[i] + \" contains {} cells by {} genes\".format(len(results[sample_id[i]].obs), len(results[sample_id[i]].var)))\n",
        "\n",
        "  results[sample_id[i]].obs[\"cell_counts\"] = results[sample_id[i]].X.sum(axis=1)\n",
        "  results[sample_id[i]].var[\"gene_counts\"] = nd(results[sample_id[i]].X.sum(axis=0))\n",
        "\n",
        "  results[sample_id[i]].obs[\"n_genes\"] = nd((results[sample_id[i]].X>0).sum(axis=1))\n",
        "  results[sample_id[i]].var[\"n_cells\"] = nd((results[sample_id[i]].X>0).sum(axis=0))\n",
        "\n",
        "  mito_genes = results[sample_id[i]].var_names.str.startswith(\"MT-\" or \"mt-\") \n",
        "  results[sample_id[i]].obs[\"percent_mito\"] = results[sample_id[i]][:,mito_genes].X.sum(axis=1)/results[sample_id[i]].X.sum(axis=1)*100\n",
        "\n",
        "  # Changing the name of the index is necessary to write the file (it won't work with duplicated names)\n",
        "  results[sample_id[i]].var.index.name = \"index\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDAUH3eH_2RA"
      },
      "source": [
        "## Assign filters for each matrix individually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukinuaKk_6Po"
      },
      "source": [
        "# Modify this manually to change sample after having assigned the \"expected_num_cells\" and \"mito_criteria\" parameters\n",
        "samp_n = 0\n",
        "\n",
        "\n",
        "# Filtering criteria\n",
        "cell_threshold = 100\n",
        "gene_threshold = 3\n",
        "\n",
        "mito_criteria = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "a5wZB5pEfwNs"
      },
      "source": [
        "\n",
        "expected_num_cells = 3500#@param {type:\"integer\"}\n",
        "knee = np.sort(nd(results[sample_id[samp_n]].X.sum(axis=1)))[::-1]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "x = knee\n",
        "y = range(len(knee))\n",
        "\n",
        "ax.loglog(x, y, linewidth=5, color=\"g\")\n",
        "\n",
        "ax.axvline(x=knee[expected_num_cells], linewidth=3, color=\"k\")\n",
        "ax.axhline(y=expected_num_cells, linewidth=3, color=\"k\")\n",
        "\n",
        "ax.set_xlabel(\"UMI Counts\")\n",
        "ax.set_ylabel(\"Set of Barcodes\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "cell_threshold = knee[expected_num_cells]\n",
        "\n",
        "results[\"cell_threshold\" + sample_id[samp_n]] = knee[expected_num_cells]\n",
        "\n",
        "print (\"Cells were filtered down to \" + str(expected_num_cells) + \" with at least \" + str(cell_threshold) + \" UMIs\")\n",
        "\n",
        "\n",
        "mito_criteria = 7#@param {type:\"integer\"}\n",
        "results[\"mito_criteria\" + sample_id[samp_n]] = mito_criteria\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "\n",
        "\n",
        "x = nd(results[sample_id[samp_n]].obs[\"cell_counts\"][results[sample_id[samp_n]].obs[\"cell_counts\"] > cell_threshold])\n",
        "y = nd(results[sample_id[samp_n]].obs[\"percent_mito\"][results[sample_id[samp_n]].obs[\"cell_counts\"] > cell_threshold])\n",
        "\n",
        "ax.scatter(x, y, color=\"green\", alpha=0.1)\n",
        "\n",
        "ax.axhline(y=mito_criteria, linestyle=\"--\", color=\"k\")\n",
        "\n",
        "\n",
        "ax.set_xlabel(\"UMI Counts\")\n",
        "ax.set_ylabel(\"Percent mito\")\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"We select \" + str(mito_criteria) + \" % as the mitochondrial content threshold\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP9j2ouPq9KY"
      },
      "source": [
        "# Filter matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE51WUA3gVmG"
      },
      "source": [
        "for i in range(no_samples):\n",
        "  results[sample_id[i]].obs[\"pass_count_filter\"] = results[sample_id[i]].obs[\"cell_counts\"] > results[\"cell_threshold\" + sample_id[i]]\n",
        "  results[sample_id[i]].obs[\"pass_mito_filter\"] = results[sample_id[i]].obs.percent_mito < results[\"mito_criteria\" + sample_id[i]]\n",
        "  results[sample_id[i]].var[\"pass_gene_filter\"] = results[sample_id[i]].var[\"n_cells\"] > gene_threshold\n",
        "\n",
        "  cell_mask = np.logical_and(results[sample_id[i]].obs[\"pass_count_filter\"].values, results[sample_id[i]].obs[\"pass_mito_filter\"].values)\n",
        "  gene_mask = results[sample_id[i]].var[\"pass_gene_filter\"].values\n",
        "\n",
        "  print(\"Current Shape: {:,} cells x {:,} genes\".format(results[sample_id[i]].shape[0], results[sample_id[i]].shape[1]))\n",
        "  print(\"    New shape: {:,} cells x {:,} genes\".format(cell_mask.sum(), gene_mask.sum()))\n",
        "  results[\"data_\" + sample_id[i]] = results[sample_id[i]][cell_mask, gene_mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxPA81yj4TlU"
      },
      "source": [
        "# Anotate and write the Anndata object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-q_Qj2U4kDU"
      },
      "source": [
        "for i in range(no_samples):\n",
        "\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"database_id\"] = database_id[i]\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"tissue\"] = tissue[i]\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"cell_type\"] = cell_type[i]\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"sample_id\"] = sample_id[i]\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"condition\"] = condition[i]\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"species\"] = species[i]\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"technology\"] = technology[i]\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"paper\"] = paper[i]\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"figure\"] = figure[i]\n",
        "\n",
        "\n",
        "%cd /content\n",
        "\n",
        "for i in range(no_samples):\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].write(\"result\" + sample_id[i])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}