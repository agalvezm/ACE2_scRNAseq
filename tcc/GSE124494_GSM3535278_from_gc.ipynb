{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of GSE124494_GSM3535278.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agalvezm/ACE2_scRNAseq/blob/master/tcc/GSE124494_GSM3535278_from_gc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9ryXluJsJw9"
      },
      "source": [
        "# GSE124494_GSM3535278"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFpTebxCffSC"
      },
      "source": [
        "This notebook uses the filtered count matrix resulting from the following google colab notebook. https://github.com/agalvezm/ACE2_scRNAseq/blob/master/notebooks_countmatrices/GSE124494_GSM3535278.ipynb Please run the notebook above and upload the results file in /content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BiFt2wu4aLh",
        "outputId": "6c302dcc-5e09-4387-f185-5938aa4a3be8"
      },
      "source": [
        "# Install SRA-toolkit \n",
        "!wget \"http://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-centos_linux64.tar.gz\"\n",
        "\n",
        "! tar -xzf sratoolkit.current-centos_linux64.tar.gz\n",
        "\n",
        "# Add to path\n",
        "import os\n",
        "os.environ['PATH'] += \":/content/sratoolkit.2.11.0-centos_linux64/bin\"\n",
        "\n",
        "# Configure\n",
        "!vdb-config --interactive\n",
        "\n",
        "# Import packages\n",
        "\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-02 07:53:28--  http://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-centos_linux64.tar.gz\n",
            "Resolving ftp-trace.ncbi.nlm.nih.gov (ftp-trace.ncbi.nlm.nih.gov)... 165.112.9.228, 165.112.9.229, 2607:f220:41e:250::10, ...\n",
            "Connecting to ftp-trace.ncbi.nlm.nih.gov (ftp-trace.ncbi.nlm.nih.gov)|165.112.9.228|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-centos_linux64.tar.gz [following]\n",
            "--2021-04-02 07:53:28--  https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-centos_linux64.tar.gz\n",
            "Connecting to ftp-trace.ncbi.nlm.nih.gov (ftp-trace.ncbi.nlm.nih.gov)|165.112.9.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 99139357 (95M) [application/x-gzip]\n",
            "Saving to: ‘sratoolkit.current-centos_linux64.tar.gz’\n",
            "\n",
            "sratoolkit.current- 100%[===================>]  94.55M  62.7MB/s    in 1.5s    \n",
            "\n",
            "2021-04-02 07:53:30 (62.7 MB/s) - ‘sratoolkit.current-centos_linux64.tar.gz’ saved [99139357/99139357]\n",
            "\n",
            "\u001b[2J\u001b[?25l\u001b[?1000h\u001b[?1002h2021-04-02T07:53:33 vdb-config.2.11.0 fatal: SIGNAL - Segmentation fault \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU4XegJlo2Na"
      },
      "source": [
        "# List of SRAs to download and transform. Copy paste from excel as string\n",
        "SRAs = \"SRR8387860\tSRR8387861\tSRR8387862\tSRR8387863\tSRR8387864\tSRR8387865\tSRR8387866\tSRR8387867\tSRR8387868\"\n",
        "\n",
        "SRAs = SRAs.split()\n",
        "\n",
        "# SRA to delete, usually the index file, which get downloaded because we include technical reads. \n",
        "# It varies so check in the SRA website\n",
        "SRA_to_delete = \"3\"\n",
        "\n",
        "\n",
        "SRAs_to_keep = np.setdiff1d([\"1\", \"2\", \"3\"], [SRA_to_delete])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3uDp_jCpfhZ",
        "outputId": "fb595541-058f-4311-f6b6-511ff4c4afdd"
      },
      "source": [
        "for sra in SRAs:\n",
        "  \"\"\"\n",
        "  Downloads SRAs and transforms to compressed fastq file. Remove index reads and original SRA\n",
        "  \"\"\"\n",
        "  # Download SRA\n",
        "  !prefetch $sra\n",
        "\n",
        "  # Convert to fastq. Biological reads are usually considered technicals in 10x so do not skip them.\n",
        "  fastq_dump_cmd = \"fastq-dump -F --gzip --readids --split-files \" + sra + \"/\" + sra +\".sra\"\n",
        "  !$fastq_dump_cmd\n",
        "\n",
        "  # Remove files\n",
        "  rm_cmd_1 = \"rm \" + sra + \"/\" + sra + \".sra\"\n",
        "  rm_cmd_2 = \"rm \" + sra + \"_\" + SRA_to_delete + \".fastq.gz\" \n",
        "  !$rm_cmd_1\n",
        "  !$rm_cmd_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2021-04-02T07:54:38 prefetch.2.11.0: 1) Downloading 'SRR8387860'...\n",
            "2021-04-02T07:54:38 prefetch.2.11.0:  Downloading via HTTPS...\n",
            "2021-04-02T07:55:27 prefetch.2.11.0:  HTTPS download succeed\n",
            "2021-04-02T07:55:32 prefetch.2.11.0:  'SRR8387860' is valid\n",
            "2021-04-02T07:55:32 prefetch.2.11.0: 1) 'SRR8387860' was downloaded successfully\n",
            "2021-04-02T07:55:32 prefetch.2.11.0: 'SRR8387860' has 0 unresolved dependencies\n",
            "Read 49121164 spots for SRR8387860/SRR8387860.sra\n",
            "Written 49121164 spots for SRR8387860/SRR8387860.sra\n",
            "\n",
            "2021-04-02T08:24:23 prefetch.2.11.0: 1) Downloading 'SRR8387861'...\n",
            "2021-04-02T08:24:23 prefetch.2.11.0:  Downloading via HTTPS...\n",
            "2021-04-02T08:25:19 prefetch.2.11.0:  HTTPS download succeed\n",
            "2021-04-02T08:25:24 prefetch.2.11.0:  'SRR8387861' is valid\n",
            "2021-04-02T08:25:24 prefetch.2.11.0: 1) 'SRR8387861' was downloaded successfully\n",
            "2021-04-02T08:25:24 prefetch.2.11.0: 'SRR8387861' has 0 unresolved dependencies\n",
            "Read 49860227 spots for SRR8387861/SRR8387861.sra\n",
            "Written 49860227 spots for SRR8387861/SRR8387861.sra\n",
            "\n",
            "2021-04-02T08:54:30 prefetch.2.11.0: 1) Downloading 'SRR8387862'...\n",
            "2021-04-02T08:54:30 prefetch.2.11.0:  Downloading via HTTPS...\n",
            "2021-04-02T08:55:25 prefetch.2.11.0:  HTTPS download succeed\n",
            "2021-04-02T08:55:30 prefetch.2.11.0:  'SRR8387862' is valid\n",
            "2021-04-02T08:55:30 prefetch.2.11.0: 1) 'SRR8387862' was downloaded successfully\n",
            "2021-04-02T08:55:30 prefetch.2.11.0: 'SRR8387862' has 0 unresolved dependencies\n",
            "Read 55010022 spots for SRR8387862/SRR8387862.sra\n",
            "Written 55010022 spots for SRR8387862/SRR8387862.sra\n",
            "\n",
            "2021-04-02T09:27:04 prefetch.2.11.0: 1) Downloading 'SRR8387863'...\n",
            "2021-04-02T09:27:04 prefetch.2.11.0:  Downloading via HTTPS...\n",
            "2021-04-02T09:27:56 prefetch.2.11.0:  HTTPS download succeed\n",
            "2021-04-02T09:28:01 prefetch.2.11.0:  'SRR8387863' is valid\n",
            "2021-04-02T09:28:01 prefetch.2.11.0: 1) 'SRR8387863' was downloaded successfully\n",
            "2021-04-02T09:28:01 prefetch.2.11.0: 'SRR8387863' has 0 unresolved dependencies\n",
            "Read 51063679 spots for SRR8387863/SRR8387863.sra\n",
            "Written 51063679 spots for SRR8387863/SRR8387863.sra\n",
            "\n",
            "2021-04-02T09:57:52 prefetch.2.11.0: 1) Downloading 'SRR8387864'...\n",
            "2021-04-02T09:57:52 prefetch.2.11.0:  Downloading via HTTPS...\n",
            "2021-04-02T09:58:41 prefetch.2.11.0:  HTTPS download succeed\n",
            "2021-04-02T09:58:46 prefetch.2.11.0:  'SRR8387864' is valid\n",
            "2021-04-02T09:58:46 prefetch.2.11.0: 1) 'SRR8387864' was downloaded successfully\n",
            "2021-04-02T09:58:46 prefetch.2.11.0: 'SRR8387864' has 0 unresolved dependencies\n",
            "Read 50984697 spots for SRR8387864/SRR8387864.sra\n",
            "Written 50984697 spots for SRR8387864/SRR8387864.sra\n",
            "\n",
            "2021-04-02T10:28:33 prefetch.2.11.0: 1) Downloading 'SRR8387865'...\n",
            "2021-04-02T10:28:33 prefetch.2.11.0:  Downloading via HTTPS...\n",
            "2021-04-02T10:29:10 prefetch.2.11.0:  HTTPS download succeed\n",
            "2021-04-02T10:29:14 prefetch.2.11.0:  'SRR8387865' is valid\n",
            "2021-04-02T10:29:14 prefetch.2.11.0: 1) 'SRR8387865' was downloaded successfully\n",
            "2021-04-02T10:29:14 prefetch.2.11.0: 'SRR8387865' has 0 unresolved dependencies\n",
            "Read 46072469 spots for SRR8387865/SRR8387865.sra\n",
            "Written 46072469 spots for SRR8387865/SRR8387865.sra\n",
            "\n",
            "2021-04-02T10:46:34 prefetch.2.11.0: 1) Downloading 'SRR8387866'...\n",
            "2021-04-02T10:46:34 prefetch.2.11.0:  Downloading via HTTPS...\n",
            "2021-04-02T10:47:18 prefetch.2.11.0:  HTTPS download succeed\n",
            "2021-04-02T10:47:22 prefetch.2.11.0:  'SRR8387866' is valid\n",
            "2021-04-02T10:47:22 prefetch.2.11.0: 1) 'SRR8387866' was downloaded successfully\n",
            "2021-04-02T10:47:22 prefetch.2.11.0: 'SRR8387866' has 0 unresolved dependencies\n",
            "Read 45805773 spots for SRR8387866/SRR8387866.sra\n",
            "Written 45805773 spots for SRR8387866/SRR8387866.sra\n",
            "\n",
            "2021-04-02T11:14:28 prefetch.2.11.0: 1) Downloading 'SRR8387867'...\n",
            "2021-04-02T11:14:28 prefetch.2.11.0:  Downloading via HTTPS...\n",
            "2021-04-02T11:15:04 prefetch.2.11.0:  HTTPS download succeed\n",
            "2021-04-02T11:15:08 prefetch.2.11.0:  'SRR8387867' is valid\n",
            "2021-04-02T11:15:08 prefetch.2.11.0: 1) 'SRR8387867' was downloaded successfully\n",
            "2021-04-02T11:15:08 prefetch.2.11.0: 'SRR8387867' has 0 unresolved dependencies\n",
            "Read 39274682 spots for SRR8387867/SRR8387867.sra\n",
            "Written 39274682 spots for SRR8387867/SRR8387867.sra\n",
            "\n",
            "2021-04-02T11:39:21 prefetch.2.11.0: 1) Downloading 'SRR8387868'...\n",
            "2021-04-02T11:39:21 prefetch.2.11.0:  Downloading via HTTPS...\n",
            "2021-04-02T11:40:02 prefetch.2.11.0:  HTTPS download succeed\n",
            "2021-04-02T11:40:06 prefetch.2.11.0:  'SRR8387868' is valid\n",
            "2021-04-02T11:40:06 prefetch.2.11.0: 1) 'SRR8387868' was downloaded successfully\n",
            "2021-04-02T11:40:06 prefetch.2.11.0: 'SRR8387868' has 0 unresolved dependencies\n",
            "Read 41976667 spots for SRR8387868/SRR8387868.sra\n",
            "Written 41976667 spots for SRR8387868/SRR8387868.sra\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmN2opl1qHSh"
      },
      "source": [
        "# Define fastq list to feed kb\n",
        "\n",
        "fastqs = []\n",
        "for sra in SRAs:\n",
        "  for read in SRAs_to_keep:\n",
        "    fastqs.append(sra + \"_\" + read + \".fastq.gz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tT2sVv2-XMD"
      },
      "source": [
        "## Metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggNFAQJCRh6P"
      },
      "source": [
        "# define the values for the analysis\n",
        "\n",
        "# accession id for the data\n",
        "id = \"GSE124494\"\n",
        "\n",
        "samp_id = [\"GSM3535278\"]\n",
        "\n",
        "no_samples = 1\n",
        "\n",
        "fastqs_per_sample = [1] \n",
        "\n",
        "sample_id = samp_id\n",
        "\n",
        "database_id = [id] * no_samples\n",
        "\n",
        "tissue = [\"lymph node\"] * no_samples\n",
        "\n",
        "cell_type = [\"lymphatic endothelial cells from axillary lymph node, CD45- PDPN+ CD31+\"] * no_samples\n",
        "\n",
        "condition = [\"Individual 2\"] * no_samples\n",
        "\n",
        "species = [\"human\"] * no_samples\n",
        "\n",
        "technology = [\"10xv2\"] * no_samples\n",
        "\n",
        "paper = [\"Muus et al 2020\"] * no_samples\n",
        "\n",
        "figure = [\"Fig 1 a,b  ED Fig 1 a,b,c,d  ED Fig 2 a,b,c,d,e\"] * no_samples\n",
        "\n",
        "\n",
        "# Set string variables for kb functions\n",
        "\n",
        "species_kb = species[0]\n",
        "\n",
        "technology_kb = technology[0]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPwL0-_-KSAw"
      },
      "source": [
        "# Imports and installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HSlUGZEp3oP",
        "outputId": "67a13233-becb-4c8b-8b99-a8e123fa4b0e"
      },
      "source": [
        "# install and import necessary software\n",
        "\n",
        "# Install kb and scanpy\n",
        "!pip -q install kb-python \n",
        "!pip -q install scanpy\n",
        "\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Setup\n",
        "\n",
        "import anndata\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import matplotlib.patches as mpatches\n",
        "import scanpy as sc\n",
        "from scipy import stats\n",
        "\n",
        "from collections import OrderedDict\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
        "from matplotlib import cm\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "def nd(arr):\n",
        "    return np.asarray(arr).reshape(-1)\n",
        "def yex(ax):\n",
        "    lims = [np.min([ax.get_xlim(), ax.get_ylim()]),\n",
        "            np.max([ax.get_xlim(), ax.get_ylim()])]\n",
        "\n",
        "    # now plot both limits against eachother\n",
        "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.set_xlim(lims)\n",
        "    ax.set_ylim(lims)\n",
        "    return ax\n",
        "\n",
        "def trim_axs(axs, N):\n",
        "    \"\"\"little helper to massage the axs list to have correct length...\"\"\"\n",
        "    axs = axs.flat\n",
        "    for ax in axs[N:]:\n",
        "        ax.remove()\n",
        "    return axs[:N]\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "fsize=20\n",
        "\n",
        "plt.rcParams.update({'font.size': fsize})\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 59.1MB 126kB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 41.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.3MB 29.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 13.2MB 39.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 7.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 41.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 6.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 33.3MB/s \n",
            "\u001b[?25h  Building wheel for loompy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for numpy-groupies (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V6FbosVrvP4"
      },
      "source": [
        "# Downloads: index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC9oETW1pE9t",
        "outputId": "9c9e710a-7181-4a73-e7a0-37ded4cbb19f"
      },
      "source": [
        "# Download the corresponding Kallisto index to fastq folder\n",
        "!kb ref -d $species_kb -i index.idx -g t2g.txt -f1 transcriptome.fasta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-04-02 12:05:35,372]    INFO Downloading files for human from https://caltech.box.com/shared/static/v1nm7lpnqz5syh8dyzdk2zs8bglncfib.gz to tmp/v1nm7lpnqz5syh8dyzdk2zs8bglncfib.gz\n",
            "100% 2.23G/2.23G [01:48<00:00, 22.0MB/s]\n",
            "[2021-04-02 12:07:25,955]    INFO Extracting files from tmp/v1nm7lpnqz5syh8dyzdk2zs8bglncfib.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VInyuq1Dp7iz"
      },
      "source": [
        "# Process fastq files (modify kb command according to fastqs list)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6FD32x-shPe",
        "outputId": "73ae2ef8-9f5a-45a7-851b-3eaa652b55ce"
      },
      "source": [
        "fastqs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SRR8387860_1.fastq.gz',\n",
              " 'SRR8387860_2.fastq.gz',\n",
              " 'SRR8387861_1.fastq.gz',\n",
              " 'SRR8387861_2.fastq.gz',\n",
              " 'SRR8387862_1.fastq.gz',\n",
              " 'SRR8387862_2.fastq.gz',\n",
              " 'SRR8387863_1.fastq.gz',\n",
              " 'SRR8387863_2.fastq.gz',\n",
              " 'SRR8387864_1.fastq.gz',\n",
              " 'SRR8387864_2.fastq.gz',\n",
              " 'SRR8387865_1.fastq.gz',\n",
              " 'SRR8387865_2.fastq.gz',\n",
              " 'SRR8387866_1.fastq.gz',\n",
              " 'SRR8387866_2.fastq.gz',\n",
              " 'SRR8387867_1.fastq.gz',\n",
              " 'SRR8387867_2.fastq.gz',\n",
              " 'SRR8387868_1.fastq.gz',\n",
              " 'SRR8387868_2.fastq.gz']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qFzPj-0kZTi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "646a402b-50b7-473e-bef7-b3bee9f820dd"
      },
      "source": [
        "\n",
        "if no_samples == 1:\n",
        "\n",
        "  # Write the kb count command as a string with all fastqs of the list as an input\n",
        "  cmd = \"kb count --h5ad -i index.idx -g t2g.txt -x \" + technology_kb + \" -o tccoutput\" + sample_id[0] + \" \"\\\n",
        "  + \"--filter bustools --tcc -t 2 --overwrite \" + \"'\" +  \"' '\".join(fastqs) + \"'\"\n",
        "  \n",
        "  # Execute it\n",
        "  !$cmd\n",
        "\n",
        "# If more than one sample, iterate through fastqs accordingly\n",
        "else:\n",
        "\n",
        "  # Initializa counter for fastq files\n",
        "  j = 0\n",
        "\n",
        "  # Loop over samples for analysis\n",
        "  for i in range(no_samples):\n",
        "\n",
        "    fastqs_to_analyze = fastqs[j:j + fastqs_per_sample[i]]\n",
        "    # Write the kb count command as a string\n",
        "    cmd = \"kb count --h5ad -i ../index.idx -g ../t2g.txt -x \" + technology_kb + \" -o tccoutput\" + sample_id[i] + \" \\\n",
        "    --filter bustools --tcc -t 2 --overwrite \" + \"'\" +  \"' '\".join(fastqs_to_analyze) + \"'\"\n",
        "\n",
        "    # Execute it\n",
        "    !$cmd\n",
        "\n",
        "    # Update j to move to the next set of fastq\n",
        "    j = j + fastqs_per_sample[i]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "results = {}\n",
        "tcc_results = {}\n",
        "for sample in sample_id:\n",
        "  # Read the filtered gene count matrix\n",
        "  results[\"data_\" + sample] = anndata.read(\"/content/result\" + sample)\n",
        "\n",
        "\n",
        "for sample in sample_id:\n",
        "  output = \"bus_raw_\" + sample + \"_from_gc\"\n",
        "  !mkdir $output\n",
        "  folder_tcc = \"tccoutput\" + sample\n",
        "\n",
        "  # read tcc matrix\n",
        "  tcc_results[sample] = anndata.read(folder_tcc + \"/counts_unfiltered/adata.h5ad\")\n",
        "  # apply gene count matrix's filter\n",
        "  tcc_results[sample] = tcc_results[sample][results[\"data_\" + sample].obs.index.values]\n",
        "  # transfer obs data\n",
        "  tcc_results[sample].obs = results[\"data_\" + sample].obs\n",
        "  # transfer metadata\n",
        "  tcc_results[sample].uns = results[\"data_\" + sample].uns\n",
        "  # write tcc matrix\n",
        "  tcc_results[sample].write(\"/content/tcc_\" + sample)\n",
        "  #gzip tcc matrix\n",
        "  cmd = \"gzip /content/tcc_\" + sample\n",
        "  !$cmd\n",
        "  #gzip unfiltered bus file\n",
        "  cmd = \"gzip \" + folder_tcc + \"/output.unfiltered.bus\"\n",
        "  !$cmd\n",
        "  # move and re-name bus file with sample id\n",
        "  cmd = \"mv \" + folder_tcc + \"/output.unfiltered.bus.gz \" + output + \"/\" + sample +\".unfiltered.bus.gz\"\n",
        "  !$cmd\n",
        "  # gzip all unfiltered counts\n",
        "  cmd = \"gzip \" + folder_tcc + \"/counts_unfiltered/*\"\n",
        "  !$cmd\n",
        "\n",
        "  # move unfiltered counts for both\n",
        "  cmd = \"mv \" + folder_tcc + \"/counts_unfiltered \" + output + \"/tcc_unfiltered\"\n",
        "  !$cmd\n",
        "\n",
        "  cmd = \"mv \" + folder_tcc + \"/*.json \" + output \n",
        "  !$cmd\n",
        "  # zip all files\n",
        "  cmd = \"zip -r \"+ output + \".zip \" + output\n",
        "  !$cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-04-02 12:08:11,613]    INFO Using index index.idx to generate BUS file to tccoutputGSM3535278 from\n",
            "[2021-04-02 12:08:11,614]    INFO         SRR8387860_1.fastq.gz\n",
            "[2021-04-02 12:08:11,614]    INFO         SRR8387860_2.fastq.gz\n",
            "[2021-04-02 12:08:11,614]    INFO         SRR8387861_1.fastq.gz\n",
            "[2021-04-02 12:08:11,614]    INFO         SRR8387861_2.fastq.gz\n",
            "[2021-04-02 12:08:11,614]    INFO         SRR8387862_1.fastq.gz\n",
            "[2021-04-02 12:08:11,614]    INFO         SRR8387862_2.fastq.gz\n",
            "[2021-04-02 12:08:11,614]    INFO         SRR8387863_1.fastq.gz\n",
            "[2021-04-02 12:08:11,614]    INFO         SRR8387863_2.fastq.gz\n",
            "[2021-04-02 12:08:11,614]    INFO         SRR8387864_1.fastq.gz\n",
            "[2021-04-02 12:08:11,614]    INFO         SRR8387864_2.fastq.gz\n",
            "[2021-04-02 12:08:11,614]    INFO         SRR8387865_1.fastq.gz\n",
            "[2021-04-02 12:08:11,614]    INFO         SRR8387865_2.fastq.gz\n",
            "[2021-04-02 12:08:11,614]    INFO         SRR8387866_1.fastq.gz\n",
            "[2021-04-02 12:08:11,615]    INFO         SRR8387866_2.fastq.gz\n",
            "[2021-04-02 12:08:11,615]    INFO         SRR8387867_1.fastq.gz\n",
            "[2021-04-02 12:08:11,615]    INFO         SRR8387867_2.fastq.gz\n",
            "[2021-04-02 12:08:11,615]    INFO         SRR8387868_1.fastq.gz\n",
            "[2021-04-02 12:08:11,615]    INFO         SRR8387868_2.fastq.gz\n",
            "[2021-04-02 12:43:16,303]    INFO Sorting BUS file tccoutputGSM3535278/output.bus to tccoutputGSM3535278/tmp/output.s.bus\n",
            "[2021-04-02 12:44:55,626]    INFO Whitelist not provided\n",
            "[2021-04-02 12:44:55,631]    INFO Copying pre-packaged 10XV2 whitelist to tccoutputGSM3535278\n",
            "[2021-04-02 12:44:55,807]    INFO Inspecting BUS file tccoutputGSM3535278/tmp/output.s.bus\n",
            "[2021-04-02 12:45:23,569]    INFO Correcting BUS records in tccoutputGSM3535278/tmp/output.s.bus to tccoutputGSM3535278/tmp/output.s.c.bus with whitelist tccoutputGSM3535278/10xv2_whitelist.txt\n",
            "[2021-04-02 12:45:46,818]    INFO Sorting BUS file tccoutputGSM3535278/tmp/output.s.c.bus to tccoutputGSM3535278/output.unfiltered.bus\n",
            "[2021-04-02 12:46:50,034]    INFO Generating count matrix tccoutputGSM3535278/counts_unfiltered/cells_x_tcc from BUS file tccoutputGSM3535278/output.unfiltered.bus\n",
            "[2021-04-02 12:48:24,107]    INFO Reading matrix tccoutputGSM3535278/counts_unfiltered/cells_x_tcc.mtx\n",
            "[2021-04-02 12:49:39,359]    INFO Writing matrix to h5ad tccoutputGSM3535278/counts_unfiltered/adata.h5ad\n",
            "[2021-04-02 12:53:52,425]    INFO Filtering with bustools\n",
            "[2021-04-02 12:53:52,425]    INFO Generating whitelist tccoutputGSM3535278/filter_barcodes.txt from BUS file tccoutputGSM3535278/output.unfiltered.bus\n",
            "[2021-04-02 12:53:53,570]    INFO Correcting BUS records in tccoutputGSM3535278/output.unfiltered.bus to tccoutputGSM3535278/tmp/output.unfiltered.c.bus with whitelist tccoutputGSM3535278/filter_barcodes.txt\n",
            "[2021-04-02 12:54:12,416]    INFO Sorting BUS file tccoutputGSM3535278/tmp/output.unfiltered.c.bus to tccoutputGSM3535278/output.filtered.bus\n",
            "[2021-04-02 12:55:15,758]    INFO Generating count matrix tccoutputGSM3535278/counts_filtered/cells_x_tcc from BUS file tccoutputGSM3535278/output.filtered.bus\n",
            "[2021-04-02 12:56:45,420]    INFO Reading matrix tccoutputGSM3535278/counts_filtered/cells_x_tcc.mtx\n",
            "[2021-04-02 12:57:58,340]    INFO Writing matrix to h5ad tccoutputGSM3535278/counts_filtered/adata.h5ad\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  adding: bus_raw_GSM3535278_from_gc/ (stored 0%)\n",
            "  adding: bus_raw_GSM3535278_from_gc/kb_info.json (deflated 79%)\n",
            "  adding: bus_raw_GSM3535278_from_gc/GSM3535278.unfiltered.bus.gz (deflated 4%)\n",
            "  adding: bus_raw_GSM3535278_from_gc/tcc_unfiltered/ (stored 0%)\n",
            "  adding: bus_raw_GSM3535278_from_gc/tcc_unfiltered/adata.h5ad.gz (deflated 4%)\n",
            "  adding: bus_raw_GSM3535278_from_gc/tcc_unfiltered/cells_x_tcc.ec.txt.gz (deflated 1%)\n",
            "  adding: bus_raw_GSM3535278_from_gc/tcc_unfiltered/cells_x_tcc.barcodes.txt.gz (deflated 1%)\n",
            "  adding: bus_raw_GSM3535278_from_gc/tcc_unfiltered/cells_x_tcc.mtx.gz (deflated 0%)\n",
            "  adding: bus_raw_GSM3535278_from_gc/inspect.json (deflated 57%)\n",
            "  adding: bus_raw_GSM3535278_from_gc/run_info.json (deflated 60%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}