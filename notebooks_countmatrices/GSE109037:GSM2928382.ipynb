{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GSE109037:GSM2928382",
      "provenance": [],
      "collapsed_sections": [
        "FPwL0-_-KSAw",
        "7V6FbosVrvP4"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agalvezm/ACE2_scRNAseq/blob/master/notebooks_countmatrices/GSE109037%3AGSM2928382.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9ryXluJsJw9"
      },
      "source": [
        "#GSE109037:GSM2928382"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggNFAQJCRh6P",
        "outputId": "12717d1b-2352-404c-a6cc-92bd61744085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# define the values for the analysis\n",
        "\n",
        "# accession id for the data\n",
        "id = \"GSE109037\"\n",
        "\n",
        "# If only bam available files, set bam = True, Fill link and filename\n",
        "bam = True\n",
        "if bam:\n",
        "  # Assign link to python variable\n",
        "  link_to_bam = \"https://sra-pub-src-1.s3.amazonaws.com/SRR6459192/AdultHuman_17_5_possorted_genome_bam.bam.1\"\n",
        "  \n",
        "  # Assigns the link to the bash variable BAM_LINK. To be used by wget\n",
        "  %env BAM_LINK=$link_to_bam\n",
        "\n",
        "  # Assign filename to python variable. Used to convert to fastq and remove bam file to fastq after conversion\n",
        "\n",
        "  bam_filename=\"AdultHuman_17_5_possorted_genome_bam.bam.1\"\n",
        "\n",
        "if not bam:\n",
        "  fastqs = [\"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR645/008/SRR6459188/SRR6459188.fastq.gz\"]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: BAM_LINK=https://sra-pub-src-1.s3.amazonaws.com/SRR6459192/AdultHuman_17_5_possorted_genome_bam.bam.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R3tPDqnoJUn"
      },
      "source": [
        "no_samples = 1\n",
        "\n",
        "database_id = [id] * no_samples\n",
        "\n",
        "tissue = [\"testis\"] * no_samples\n",
        "\n",
        "cell_type = [\"spermatogonia\"] * no_samples\n",
        "\n",
        "sample_id = [\"GSM2928382\"] * no_samples\n",
        "\n",
        "condition = [\"17-5 adult human\"] * no_samples\n",
        "\n",
        "species = [\"human\"] * no_samples\n",
        "\n",
        "technology = [\"10xv2\"] * no_samples\n",
        "\n",
        "paper = [\"Muus et al 2020\"] * no_samples\n",
        "\n",
        "figure = [\"Fig 1 a,b  ED Fig 1 a,b,c,d  ED Fig 2 a,b,c,d,e\"] * no_samples\n",
        "\n",
        "\n",
        "# Set string variables for kb functions\n",
        "\n",
        "species_kb = species[0]\n",
        "\n",
        "technology_kb = technology[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPwL0-_-KSAw"
      },
      "source": [
        "# Imports and installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HSlUGZEp3oP",
        "outputId": "80ca8ea6-c56a-4233-9c41-04642151bf5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# install and import necessary software\n",
        "\n",
        "# Install kb and scanpy\n",
        "!pip -q install kb-python \n",
        "!pip -q install scanpy\n",
        "\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Setup\n",
        "\n",
        "import anndata\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import matplotlib.patches as mpatches\n",
        "import scanpy as sc\n",
        "from scipy import stats\n",
        "\n",
        "from collections import OrderedDict\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
        "from matplotlib import cm\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "def nd(arr):\n",
        "    return np.asarray(arr).reshape(-1)\n",
        "def yex(ax):\n",
        "    lims = [np.min([ax.get_xlim(), ax.get_ylim()]),\n",
        "            np.max([ax.get_xlim(), ax.get_ylim()])]\n",
        "\n",
        "    # now plot both limits against eachother\n",
        "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.set_xlim(lims)\n",
        "    ax.set_ylim(lims)\n",
        "    return ax\n",
        "\n",
        "def trim_axs(axs, N):\n",
        "    \"\"\"little helper to massage the axs list to have correct length...\"\"\"\n",
        "    axs = axs.flat\n",
        "    for ax in axs[N:]:\n",
        "        ax.remove()\n",
        "    return axs[:N]\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "fsize=20\n",
        "\n",
        "plt.rcParams.update({'font.size': fsize})\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 35.4MB 56.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 46.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 49.2MB/s \n",
            "\u001b[?25h  Building wheel for loompy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for numpy-groupies (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 7.7MB 2.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25h  Building wheel for sinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V6FbosVrvP4"
      },
      "source": [
        "# Downloads: (bam (if bam) and index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q46hw4zqKUPS",
        "outputId": "0cddfca6-172d-45d7-92c0-a5298f7ab2c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "if bam:\n",
        "\n",
        "  # Install bamtofastq from 10x website (only bam files available)\n",
        "  !wget http://cf.10xgenomics.com/misc/bamtofastq-1.2.0\n",
        "  !chmod +x bamtofastq-1.2.0\n",
        "  # Download the bam file\n",
        "  !wget -- continue ${BAM_LINK}\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-25 23:13:39--  http://cf.10xgenomics.com/misc/bamtofastq-1.2.0\n",
            "Resolving cf.10xgenomics.com (cf.10xgenomics.com)... 104.18.1.173, 104.18.0.173, 2606:4700::6812:1ad, ...\n",
            "Connecting to cf.10xgenomics.com (cf.10xgenomics.com)|104.18.1.173|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cf.10xgenomics.com/misc/bamtofastq-1.2.0 [following]\n",
            "--2020-09-25 23:13:39--  https://cf.10xgenomics.com/misc/bamtofastq-1.2.0\n",
            "Connecting to cf.10xgenomics.com (cf.10xgenomics.com)|104.18.1.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13288280 (13M) [binary/octet-stream]\n",
            "Saving to: ‘bamtofastq-1.2.0’\n",
            "\n",
            "bamtofastq-1.2.0    100%[===================>]  12.67M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-09-25 23:13:39 (188 MB/s) - ‘bamtofastq-1.2.0’ saved [13288280/13288280]\n",
            "\n",
            "--2020-09-25 23:13:40--  http://continue/\n",
            "Resolving continue (continue)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘continue’\n",
            "--2020-09-25 23:13:40--  https://sra-pub-src-1.s3.amazonaws.com/SRR6459192/AdultHuman_17_5_possorted_genome_bam.bam.1\n",
            "Resolving sra-pub-src-1.s3.amazonaws.com (sra-pub-src-1.s3.amazonaws.com)... 52.217.13.108\n",
            "Connecting to sra-pub-src-1.s3.amazonaws.com (sra-pub-src-1.s3.amazonaws.com)|52.217.13.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35252257183 (33G) [application/x-troff-man]\n",
            "Saving to: ‘AdultHuman_17_5_possorted_genome_bam.bam.1’\n",
            "\n",
            "_5_possorted_genome  27%[====>               ]   9.19G  17.0MB/s    eta 25m 16s"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDQlrjtqNF0m"
      },
      "source": [
        "if bam:\n",
        "  # Convert to fastq\n",
        "  !./bamtofastq-1.2.0 --reads-per-fastq=500000000 $bam_filename ./fastqs\\\n",
        "\n",
        "  # Remove original bam file to save space\n",
        "  !rm $bam_filename\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXRDRphvqcLe"
      },
      "source": [
        "# Store fastq names on a list\n",
        "\n",
        "if bam:\n",
        "  # cd into fastqs folder\n",
        "  %cd /content/fastqs\n",
        "\n",
        "  #store the name of the folder generated by bamtofastq\n",
        "  _filename = os.listdir()[0]\n",
        "\n",
        "  # cd into that folder\n",
        "  %cd $_filename\n",
        "\n",
        "  # store fastq names in a list\n",
        "  fastqs = os.listdir()\n",
        "\n",
        "\n",
        "  # Remove I1 and R3 reads not relevant for our analysis\n",
        "\n",
        "  print (\"\\n\\nThis is the complete list of fastqs:\\n -----------\")\n",
        "  for elem in fastqs:\n",
        "    print (elem)\n",
        "\n",
        "  for elem in fastqs:\n",
        "    if re.search(\"_R3_\", elem) or re.search(\"_I1_\", elem):\n",
        "      fastqs.remove(elem)\n",
        "\n",
        "  print (\"\\n\\nThis is the filtered list of fastqs:\\n -----------\")\n",
        "  for elem in fastqs:\n",
        "    print (elem)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLVS8aB7Dm6J"
      },
      "source": [
        "if bam:\n",
        "  # sort fastqs alphabetically to get R1 and R2 in order\n",
        "  fastqs = sorted(fastqs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC9oETW1pE9t"
      },
      "source": [
        "if bam:\n",
        "  # Download the corresponding Kallisto index to folder containing fastqs\n",
        "  !kb ref -d $species_kb -i index.idx -g t2g.txt -f1 transcriptome.fasta\n",
        "\n",
        "if not bam:\n",
        "  %cd /content\n",
        "\n",
        "  # Download the corresponding Kallisto index to content folder\n",
        "  !kb ref -d $species_kb -i index.idx -g t2g.txt -f1 transcriptome.fasta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHVNa51Cp9Nr"
      },
      "source": [
        "print(fastqs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VInyuq1Dp7iz"
      },
      "source": [
        "# Process fastq files (modify kb command according to fastqs list)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcqtBuH-pRaX"
      },
      "source": [
        "fastqs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qFzPj-0kZTi"
      },
      "source": [
        "# Specify the sample number and whether they are paired end\n",
        "number_of_samples = 1\n",
        "paired_end = True \n",
        "\n",
        "# Initialize counter for fastq files\n",
        "j = 0\n",
        "# Loop over samples for analysis\n",
        "for i in range(number_of_samples):\n",
        "\n",
        "  # 0-based Index for fastqs:\n",
        "  # Write the kb count command as a string\n",
        "  cmd = \"kb count --h5ad -i index.idx -g t2g.txt -x \" + technology_kb + \" -o output\" + sample_id[i] + \" \\\n",
        "  --filter bustools -t 2 --overwrite \" +\\\n",
        "  fastqs[j] + \" \" + fastqs[j+1]\n",
        "  # Execute it\n",
        "  !$cmd\n",
        "  # Update j to get the two next fastqs\n",
        "  if paired_end:\n",
        "    j = j + 2\n",
        "  else:\n",
        "    j = j + 1\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDijOZzrqhN2"
      },
      "source": [
        "# Load unfiltered matrix and assign filters to each matrix individually"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkNLZh_pNFFw"
      },
      "source": [
        "## Load the unfiltered matrix (check dimensions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PppRNeV8AIyw"
      },
      "source": [
        "# Define dict to store data\n",
        "results = {}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKmtGf3c_BiZ",
        "cellView": "both"
      },
      "source": [
        "# load the unfiltered matrix\n",
        "for i in range(number_of_samples):\n",
        "  results[sample_id[i]] = anndata.read_h5ad(\"output\" + sample_id[i] + \"/counts_unfiltered/adata.h5ad\")\n",
        "  results[sample_id[i]].var[\"gene_id\"] = results[sample_id[i]].var.index.values\n",
        "\n",
        "  t2g = pd.read_csv(\"t2g.txt\", header=None, names=[\"tid\", \"gene_id\", \"gene_name\"], sep=\"\\t\")\n",
        "  t2g.index = t2g.gene_id\n",
        "  t2g = t2g.loc[~t2g.index.duplicated(keep='first')]\n",
        "\n",
        "  results[sample_id[i]].var[\"gene_name\"] = results[sample_id[i]].var.gene_id.map(t2g[\"gene_name\"])\n",
        "  results[sample_id[i]].var.index = results[sample_id[i]].var[\"gene_name\"]\n",
        "  print(\"The unfiltered matrix \" + sample_id[i] + \" contains {} cells by {} genes\".format(len(results[sample_id[i]].obs), len(results[sample_id[i]].var)))\n",
        "\n",
        "  results[sample_id[i]].obs[\"cell_counts\"] = results[sample_id[i]].X.sum(axis=1)\n",
        "  results[sample_id[i]].var[\"gene_counts\"] = nd(results[sample_id[i]].X.sum(axis=0))\n",
        "\n",
        "  results[sample_id[i]].obs[\"n_genes\"] = nd((results[sample_id[i]].X>0).sum(axis=1))\n",
        "  results[sample_id[i]].var[\"n_cells\"] = nd((results[sample_id[i]].X>0).sum(axis=0))\n",
        "\n",
        "  mito_genes = results[sample_id[i]].var_names.str.startswith(\"MT-\" or \"mt-\") \n",
        "  results[sample_id[i]].obs[\"percent_mito\"] = results[sample_id[i]][:,mito_genes].X.sum(axis=1)/results[sample_id[i]].X.sum(axis=1)*100\n",
        "\n",
        "  # Changing the name of the index is necessary to write the file (it won't work with duplicated names)\n",
        "  results[sample_id[i]].var.index.name = \"index\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDAUH3eH_2RA"
      },
      "source": [
        "## Assign filters for each matrix individually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukinuaKk_6Po"
      },
      "source": [
        "# Modify this manually to change sample after having assigned the \"expected_num_cells\" and \"mito_criteria\" parameters\n",
        "samp_n = 0\n",
        "\n",
        "\n",
        "# Filtering criteria\n",
        "cell_threshold = 100\n",
        "gene_threshold = 3\n",
        "\n",
        "mito_criteria = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5wZB5pEfwNs",
        "cellView": "form"
      },
      "source": [
        "\n",
        "expected_num_cells = 10000#@param {type:\"integer\"}\n",
        "knee = np.sort(nd(results[sample_id[i]].X.sum(axis=1)))[::-1]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "x = knee\n",
        "y = range(len(knee))\n",
        "\n",
        "ax.loglog(x, y, linewidth=5, color=\"g\")\n",
        "\n",
        "ax.axvline(x=knee[expected_num_cells], linewidth=3, color=\"k\")\n",
        "ax.axhline(y=expected_num_cells, linewidth=3, color=\"k\")\n",
        "\n",
        "ax.set_xlabel(\"UMI Counts\")\n",
        "ax.set_ylabel(\"Set of Barcodes\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "cell_threshold = knee[expected_num_cells]\n",
        "\n",
        "results[\"cell_threshold\" + sample_id[samp_n]] = knee[expected_num_cells]\n",
        "\n",
        "print (\"Cells were filtered down to \" + str(expected_num_cells) + \" with at least \" + str(cell_threshold) + \" UMIs\")\n",
        "\n",
        "\n",
        "mito_criteria = 18#@param {type:\"integer\"}\n",
        "results[\"mito_criteria\" + sample_id[samp_n]] = mito_criteria\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "\n",
        "\n",
        "x = nd(results[sample_id[i]].obs[\"cell_counts\"][results[sample_id[i]].obs[\"cell_counts\"] > cell_threshold])\n",
        "y = nd(results[sample_id[i]].obs[\"percent_mito\"][results[sample_id[i]].obs[\"cell_counts\"] > cell_threshold])\n",
        "\n",
        "ax.scatter(x, y, color=\"green\", alpha=0.1)\n",
        "\n",
        "ax.axhline(y=mito_criteria, linestyle=\"--\", color=\"k\")\n",
        "\n",
        "\n",
        "ax.set_xlabel(\"UMI Counts\")\n",
        "ax.set_ylabel(\"Percent mito\")\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"We select \" + str(mito_criteria) + \" % as the mitochondrial content threshold\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP9j2ouPq9KY"
      },
      "source": [
        "# Filter matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE51WUA3gVmG"
      },
      "source": [
        "for i in range(number_of_samples):\n",
        "  results[sample_id[i]].obs[\"pass_count_filter\"] = results[sample_id[i]].obs[\"cell_counts\"] > results[\"cell_threshold\" + sample_id[i]]\n",
        "  results[sample_id[i]].obs[\"pass_mito_filter\"] = results[sample_id[i]].obs.percent_mito < results[\"mito_criteria\" + sample_id[i]]\n",
        "  results[sample_id[i]].var[\"pass_gene_filter\"] = results[sample_id[i]].var[\"n_cells\"] > gene_threshold\n",
        "\n",
        "  cell_mask = np.logical_and(results[sample_id[i]].obs[\"pass_count_filter\"].values, results[sample_id[i]].obs[\"pass_mito_filter\"].values)\n",
        "  gene_mask = results[sample_id[i]].var[\"pass_gene_filter\"].values\n",
        "\n",
        "  print(\"Current Shape: {:,} cells x {:,} genes\".format(results[sample_id[i]].shape[0], results[sample_id[i]].shape[1]))\n",
        "  print(\"    New shape: {:,} cells x {:,} genes\".format(cell_mask.sum(), gene_mask.sum()))\n",
        "  results[\"data_\" + sample_id[i]] = results[sample_id[i]][cell_mask, gene_mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxPA81yj4TlU"
      },
      "source": [
        "# Anotate and write the Anndata object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-q_Qj2U4kDU"
      },
      "source": [
        "for i in range(number_of_samples):\n",
        "\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"database_id\"] = database_id[samp_n]\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"tissue\"] = tissue[samp_n]\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"cell_type\"] = cell_type[samp_n]\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"sample_id\"] = sample_id[samp_n]\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"condition\"] = condition[samp_n]\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"species\"] = species[samp_n]\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"technology\"] = technology[samp_n]\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"paper\"] = paper[samp_n]\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].uns[\"figure\"] = figure[samp_n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICc77J94_Kye"
      },
      "source": [
        "%cd /content\n",
        "\n",
        "for i in range(number_of_samples):\n",
        "\n",
        "  results[\"data_\" + sample_id[i]].write(\"result\" + sample_id[i])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}